options {
  STATIC = false;
  DEBUG_PARSER = false;
  DEBUG_LOOKAHEAD = false;
  DEBUG_TOKEN_MANAGER = false;
}

PARSER_BEGIN(SmallTalkLexer)
package lexical;

public class SmallTalkLexer {
  public static void main(String[] args) throws ParseException {
    SmallTalkLexer lexer;
    if (args.length == 0) {
      System.out.println("Smalltalk Lexical Analyzer: Reading from standard input...");
      lexer = new SmallTalkLexer(System.in);
    } else if (args.length == 1) {
      System.out.println("Smalltalk Lexical Analyzer: Reading from file " + args[0]);
      try {
        lexer = new SmallTalkLexer(new java.io.FileInputStream(args[0]));
      } catch (java.io.FileNotFoundException e) {
        System.out.println("File " + args[0] + " not found.");
        return;
      }
    } else {
      System.out.println("Smalltalk Lexical Analyzer: Usage is one of:");
      System.out.println("         java SmallTalkLexer < inputfile");
      System.out.println("OR");
      System.out.println("         java SmallTalkLexer inputfile");
      return;
    }

    try {
      lexer.Start();
    } catch (ParseException e) {
      System.out.println("Syntax Error: " + e.getMessage());
    }
  }
}

PARSER_END(SmallTalkLexer)

// Ignorando espaços em branco e comentários
SKIP : {
  < TOKEN_whitespace : [" ", "\t", "\n", "\r"] >
  | < TOKEN_comment: "\"" (~["\""] | "\"\"")* "\"" > // Comentários com qualquer caractere que não seja aspas
//  | <TOKEN_separator: (<TOKEN_whitespace> | <TOKEN_comment>)* > // TODO: TIRAR DUVIDAS
}

// Definição dos tokens
// A ordem dos tokens foram definidos conforme o documento base.

TOKEN : {
    // 1) Identificadores reservados (ou palavras reservadas)
    < TOKEN_nil: "nil" >
    | < TOKEN_true: "true" >
    | < TOKEN_false: "false" >
    | < TOKEN_self: "self" >
    | < TOKEN_super: "super" >
    | < TOKEN_thisContext: "thisContext" > // TODO: EXISTE ESTA PALAVRA RESERVADA NA LINGUAGEM?

    // 2) Identificador
    // TODO: VERIFICAR SE SMALLTALK ACEITA ID COMEÇANDO DE "_"
    | < TOKEN_identifier: <TOKEN_letter> (<TOKEN_letter> | <TOKEN_digit> )* >

    // 3) CHARACTERS E DIGITOS
    | < TOKEN_digit : ["0"-"9"] > // Qualquer dígito entre 0 e 9
    | < TOKEN_uppercase_alphabetic : ["A"-"Z"] > // Letras maiúsculas de A a Z
    | < TOKEN_lowercase_alphabetic : ["a"-"z"] > // Letras minúsculas de a a z
    | < TOKEN_noncase_letter : "_" > // TODO: TIRAR DÚVIDAS
    | < TOKEN_letter :
          < TOKEN_uppercase_alphabetic > |
          < TOKEN_lowercase_alphabetic > |
          < TOKEN_noncase_letter >
      >

   // 4) Palavra chave

   /*
   * Uma palavra-chave em Smalltalk é usada para identificar mensagens
   * que aceitam argumentos. Diferentemente de outras linguagens, onde
   * palavras-chave podem ser reservadas e usadas para controlar a sintaxe,
   * em Smalltalk, as palavras-chave são parte da estrutura de mensagens
   * enviadas para objetos.*/

   | < TOKEN_keyword: <TOKEN_identifier> ":" >

   // 5) Operadores (caractres, seletores binários, retorn e atribuição).
   | < TOKEN_binaryCharacter : ["!", "%", "&", "*", "+", ",", "/", "<", "=", ">", "?", "@", "\\", "~", "|", "-"] >
   | < TOKEN_binarySelector : (<TOKEN_binaryCharacter>)+ > // Um ou mais caracteres binários consecutivos
   | < TOKEN_return_operator : "^" > // Operador de retorno
   | < TOKEN_assignment_operator : ":=" > // Operador de atribuição

   // 6) Numéricos

   // Inteiro, flutuante e racional
   | < TOKEN_integer : <TOKEN_decimal_integer> | <TOKEN_radix_integer> >
   | < TOKEN_float : <TOKEN_mantissa> (<TOKEN_expoent_letter> <TOKEN_expoent>)? >
    | < TOKEN_scaled_decimal : (<TOKEN_scaled_mantissa> "s" (<TOKEN_fractional_digits>)?) >

   | < TOKEN_radix_integer : <TOKEN_radix_specifier> "r" <TOKEN_radix_digits> > // Inteiro com base (radix)
   | < TOKEN_radix_specifier : <TOKEN_digits> > // Especificador de base (um ou mais dígitos)
   | < TOKEN_radix_digits : (<TOKEN_digit> | <TOKEN_uppercase_alphabetic> )+ > // Dígitos ou letras maiúsculas
   | < TOKEN_digits : (<TOKEN_digit>)+ > // Um ou mais dígitos
   | < TOKEN_scaled_mantissa : <TOKEN_decimal_integer> | <TOKEN_mantissa> >
   | < TOKEN_decimal_integer : <TOKEN_digits> > // Inteiro decimal
   | < TOKEN_mantissa : (<TOKEN_digits> "." <TOKEN_digits>) >
   | < TOKEN_expoent : (["-"])? <TOKEN_decimal_integer> >
   | < TOKEN_expoent_letter : ["e", "d", "q"] >
   | < TOKEN_fractional_digits : <TOKEN_decimal_integer> >

    // 7) Define um caractere entre aspas como o símbolo "$" seguido por qualquer caractere
    // Representa caracteres válidos // TODO: Tirar duvidas
    | < TOKEN_character : ["A"-"Z", "a"-"z", "0"-"9", "_", "-", "+", "*", "/", "~", "`", "!", "@", "#", "$", "%", "^", "&", "(", ")", "[", "]", "{", "}", "<", ">", ".", ",", ";", ":"] >

    | < TOKEN_quoted_character : "$" <TOKEN_character> >

    // 8) Define uma string seguida de "$"
    // Define uma string completa entre aspas simples
    | < TOKEN_quoted_string : "'" ( ~["'"] | "''" )* "'" >

    // 9) Define uma string com "$"

    /*
    * Uma string com hash é uma string entre aspas que
    * é imediatamente precedida por um sinal de
    * cerquilha.**/

    | < TOKEN_hashed_string : "#" <TOKEN_quoted_string> >

    // 10) Define um seletor binário

    /*
    * Um seletor entre aspas é um identificador, seletor
    * binário ou sequência de palavras-chave que é imediatamente
    * precedido por um sinal de libra.**/

    | < TOKEN_keyword_selector : (<TOKEN_keyword>)+ >

    | < TOKEN_quoted_selector : "#" (<TOKEN_identifier> | <TOKEN_binarySelector> | <TOKEN_keyword_selector>) >
}

// Análise léxica principal
void Start() :
{}
{
  (Token())* <EOF>
}

void Token() :
{
  Token t;
}
{
    t = <TOKEN_nil> { System.out.println("TOKEN_nil " + t.image); } |
    t = <TOKEN_true> { System.out.println("TOKEN_true " + t.image); } |
    t = <TOKEN_false> { System.out.println("TOKEN_false " + t.image); } |
    t = <TOKEN_self> { System.out.println("TOKEN_self " + t.image); } |
    t = <TOKEN_super> { System.out.println("TOKEN_super " + t.image); } |
    t = <TOKEN_thisContext> { System.out.println("TOKEN_thisContext " + t.image); } |
    //
    t = <TOKEN_identifier> { System.out.println("TOKEN_identifier " + t.image); } |
    //
    t = <TOKEN_keyword> { System.out.println("TOKEN_keyword " + t.image); } |
    //
    t = <TOKEN_binaryCharacter> { System.out.println("TOKEN_binaryCharacter " + t.image); } |
    t = <TOKEN_binarySelector> { System.out.println("TOKEN_binarySelector " + t.image); } |
    t = <TOKEN_return_operator> { System.out.println("TOKEN_return_operator " + t.image); } |
    t = <TOKEN_assignment_operator> { System.out.println("TOKEN_assignment_operator " + t.image); } |
    //
    t = <TOKEN_integer> { System.out.println("TOKEN_integer " + t.image); } |
    t = <TOKEN_float> { System.out.println("TOKEN_float " + t.image); } |
    t = <TOKEN_scaled_decimal> { System.out.println("TOKEN_scaled_decimal " + t.image); } |
    t = <TOKEN_scaled_mantissa> { System.out.println("TOKEN_scaled_mantissa " + t.image); } |
    //
    t = <TOKEN_quoted_character> { System.out.println("TOKEN_quoted_character " + t.image); } |
    //
    t = <TOKEN_quoted_string> { System.out.println("TOKEN_quoted_string " + t.image); } |
    //
    t = <TOKEN_hashed_string> { System.out.println("TOKEN_hashed_string " + t.image); } |
    //
    t = <TOKEN_quoted_selector> { System.out.println("TOKEN_quoted_selector " + t.image); }
}
